{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEbKN2kFFPQZ",
        "outputId": "24e09c00-25c3-48e1-d053-2850027b93a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/fabianavinci/guitar-chords-v2?dataset_version_number=3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 729M/729M [00:08<00:00, 85.2MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/fabianavinci/guitar-chords-v2/versions/3\n"
          ]
        }
      ],
      "source": [
        "#@title Download dataset\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"fabianavinci/guitar-chords-v2\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hi89UFMGKyx",
        "outputId": "718a8c4b-1e5b-4308-9c9b-43d12b871142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied to: /content/guitar-chords-v2\n",
            "['Training', 'Test']\n"
          ]
        }
      ],
      "source": [
        "#@title Move dataset to content folder\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "SRC = path\n",
        "DST = \"/content/guitar-chords-v2\"\n",
        "\n",
        "# nếu đã tồn tại thì xoá\n",
        "if os.path.exists(DST):\n",
        "    shutil.rmtree(DST)\n",
        "\n",
        "shutil.copytree(SRC, DST)\n",
        "\n",
        "print(\"Copied to:\", DST)\n",
        "print(os.listdir(DST))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "95G8OXttIfnl"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "BASE_DIR = \"/content/guitar-chords-v2\"\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, \"Training\")\n",
        "TEST_DIR  = os.path.join(BASE_DIR, \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbjFzb1-IktK",
        "outputId": "1cd8ab46-631e-4acb-fc2e-bcbeae5d4a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 1440\n",
            "Val samples: 320\n",
            "Chord classes: [np.str_('Am'), np.str_('Bb'), np.str_('Bdim'), np.str_('C'), np.str_('Dm'), np.str_('Em'), np.str_('F'), np.str_('G')]\n"
          ]
        }
      ],
      "source": [
        "#@title Load files\n",
        "def load_split(split_dir):\n",
        "    paths = []\n",
        "    labels = []\n",
        "\n",
        "    for chord in sorted(os.listdir(split_dir)):\n",
        "        chord_dir = os.path.join(split_dir, chord)\n",
        "        if not os.path.isdir(chord_dir):\n",
        "            continue\n",
        "\n",
        "        for wav in glob.glob(os.path.join(chord_dir, \"*.wav\")):\n",
        "            paths.append(wav)\n",
        "            labels.append(chord)\n",
        "\n",
        "    return paths, np.array(labels)\n",
        "\n",
        "train_paths, train_chords = load_split(TRAIN_DIR)\n",
        "val_paths,   val_chords   = load_split(TEST_DIR)\n",
        "\n",
        "print(\"Train samples:\", len(train_paths))\n",
        "print(\"Val samples:\", len(val_paths))\n",
        "print(\"Chord classes:\", sorted(set(train_chords)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F8g4F3_3Ixlt"
      },
      "outputs": [],
      "source": [
        "#@title Feature extraction (log mel)\n",
        "def extract_feature(path, sr=22050, n_mels=64):\n",
        "    y, sr = librosa.load(path, sr=sr, mono=True)\n",
        "\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=y, sr=sr,\n",
        "        n_mels=n_mels,\n",
        "        fmin=80, fmax=2000\n",
        "    )\n",
        "\n",
        "    logmel = np.log(mel + 1e-6)\n",
        "\n",
        "    # pool theo frequency\n",
        "    feat = logmel.mean(axis=1)              # (64,)\n",
        "    feat = feat.reshape(16, 4).mean(axis=1) # (16,)\n",
        "\n",
        "    return feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nME_bdczI4FC",
        "outputId": "8d5e80cb-280e-4b9d-a24a-5817c592d969"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extract train features: 100%|██████████| 1440/1440 [01:02<00:00, 23.13it/s]\n",
            "Extract val features: 100%|██████████| 320/320 [00:07<00:00, 44.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape: (1440, 16)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Feature matrices\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "X_train = np.stack([\n",
        "    extract_feature(p)\n",
        "    for p in tqdm(train_paths, desc=\"Extract train features\")\n",
        "])\n",
        "\n",
        "X_val = np.stack([\n",
        "    extract_feature(p)\n",
        "    for p in tqdm(val_paths, desc=\"Extract val features\")\n",
        "])\n",
        "\n",
        "print(\"Feature shape:\", X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWthaklAJvVz",
        "outputId": "46e6ef51-2d9f-45bb-d777-179e56a6c96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded classes: ['Am' 'Bb' 'Bdim' 'C' 'Dm' 'Em' 'F' 'G']\n"
          ]
        }
      ],
      "source": [
        "#@title Encode label\n",
        "le_chord = LabelEncoder()\n",
        "\n",
        "y_train = le_chord.fit_transform(train_chords)\n",
        "y_val   = le_chord.transform(val_chords)\n",
        "\n",
        "print(\"Encoded classes:\", le_chord.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TbmLPugsJzP3"
      },
      "outputs": [],
      "source": [
        "#@title Scale feature\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_val_s   = scaler.transform(X_val)\n",
        "\n",
        "scaler_mean  = scaler.mean_\n",
        "scaler_scale = scaler.scale_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URk1XSk19wzq",
        "outputId": "3ec29c04-7b61-4f2d-df5c-30db9f2b119e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "static const float CHORD_MEAN[16] = {\n",
            "  -2.03650455f, -2.26095502f, -2.45058618f, -4.14766748f, -4.66261261f, -4.88741472f, -5.50021994f, -5.58704452f,\n",
            "  -6.32571979f, -6.25388386f, -6.89863926f, -7.02966055f, -6.83384801f, -6.77439976f, -6.81123306f, -7.58411825f\n",
            "};\n",
            "\n",
            "static const float CHORD_SCALE[16] = {\n",
            "  2.53589825f, 1.97801876f, 2.00723825f, 2.00208736f, 2.12831373f, 2.20478826f, 2.28146183f, 2.42331475f,\n",
            "  2.13611270f, 2.04229769f, 2.11201004f, 2.17831763f, 2.17883348f, 2.29924031f, 2.48667369f, 2.30689137f\n",
            "};\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Export mean and scale to C array\n",
        "def to_c_array(name, arr, per_line=8):\n",
        "    print(f\"static const float {name}[{len(arr)}] = {{\")\n",
        "    for i in range(0, len(arr), per_line):\n",
        "        chunk = \", \".join(f\"{x:.8f}f\" for x in arr[i:i+per_line])\n",
        "        print(\"  \" + chunk + (\",\" if i + per_line < len(arr) else \"\"))\n",
        "    print(\"};\\n\")\n",
        "\n",
        "to_c_array(\"CHORD_MEAN\", scaler.mean_)\n",
        "to_c_array(\"CHORD_SCALE\", scaler.scale_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQeChJbAMt6M",
        "outputId": "b919a92c-e87d-4c6e-e9bd-2e0db1b84d03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (1440, 16)\n",
            "X_val shape: (320, 16)\n",
            "X_train type: <class 'numpy.ndarray'> dtype: float32\n",
            "X_val type: <class 'numpy.ndarray'> dtype: float32\n"
          ]
        }
      ],
      "source": [
        "#@title Feature shape\n",
        "print(\"X_train shape:\", X_train_s.shape)\n",
        "print(\"X_val shape:\", X_val_s.shape)\n",
        "print(\"X_train type:\", type(X_train_s), \"dtype:\", X_train_s.dtype)\n",
        "print(\"X_val type:\", type(X_val_s), \"dtype:\", X_val_s.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vB5FTScJ4HX",
        "outputId": "c29e2097-8aa7-40c6-ef1b-ede9fead3df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weight: {np.int64(0): np.float64(1.0), np.int64(1): np.float64(1.0), np.int64(2): np.float64(1.0), np.int64(3): np.float64(1.0), np.int64(4): np.float64(1.0), np.int64(5): np.float64(1.0), np.int64(6): np.float64(1.0), np.int64(7): np.float64(1.0)}\n"
          ]
        }
      ],
      "source": [
        "#@title Compute class weight\n",
        "class_weight = dict(zip(\n",
        "    np.unique(y_train),\n",
        "    compute_class_weight(\n",
        "        class_weight=\"balanced\",\n",
        "        classes=np.unique(y_train),\n",
        "        y=y_train\n",
        "    )\n",
        "))\n",
        "\n",
        "print(\"Class weight:\", class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMPO8RTtJ_ID",
        "outputId": "c28855db-4f15-4a47-ffff-05210c4946dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C=0.01 | chord acc=0.5469\n",
            "C=0.1 | chord acc=0.5906\n",
            "C=1.0 | chord acc=0.6562\n",
            "C=10.0 | chord acc=0.6594\n",
            "\n",
            "=== BEST MODEL ===\n",
            "Best C: 10.0\n",
            "Best chord ACC: 0.659375\n"
          ]
        }
      ],
      "source": [
        "#@title Training + Finetuning Logistic Regression\n",
        "C_list = [0.01, 0.1, 1.0, 10.0]\n",
        "\n",
        "best_acc = -1\n",
        "best_model = None\n",
        "best_pred = None\n",
        "best_C = None\n",
        "\n",
        "for C in C_list:\n",
        "    model = LogisticRegression(\n",
        "        C=C,\n",
        "        max_iter=1000,\n",
        "        class_weight=class_weight,\n",
        "        solver=\"lbfgs\"\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_s, y_train)\n",
        "    pred = model.predict(X_val_s)\n",
        "\n",
        "    acc = accuracy_score(y_val, pred)\n",
        "    print(f\"C={C} | chord acc={acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_model = model\n",
        "        best_pred = pred\n",
        "        best_C = C\n",
        "\n",
        "print(\"\\n=== BEST MODEL ===\")\n",
        "print(\"Best C:\", best_C)\n",
        "print(\"Best chord ACC:\", best_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjwNQVlcKpT4",
        "outputId": "a3e2667b-49fe-4fe5-c408-c30b92929c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C=0.01 | acc=0.6000\n",
            "C=0.1 | acc=0.6094\n",
            "C=1.0 | acc=0.6094\n",
            "C=10.0 | acc=0.6094\n"
          ]
        }
      ],
      "source": [
        "#@title Training + Finetuning Linear SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "C_values = [0.01, 0.1, 1.0, 10.0]\n",
        "best_acc = -1\n",
        "\n",
        "for C in C_values:\n",
        "    model = LinearSVC(\n",
        "        C=C,\n",
        "        class_weight=\"balanced\",\n",
        "        max_iter=5000\n",
        "    )\n",
        "    model.fit(X_train_s, y_train)\n",
        "    pred = model.predict(X_val_s)\n",
        "\n",
        "    acc = accuracy_score(y_val, pred)\n",
        "    print(f\"C={C} | acc={acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik-ebTDOK5ea",
        "outputId": "01bff507-ca00-4949-ab3e-9e423ab5d99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alpha=0.1 | acc=0.5594\n",
            "alpha=1.0 | acc=0.5594\n",
            "alpha=10.0 | acc=0.5656\n",
            "alpha=100.0 | acc=0.5781\n"
          ]
        }
      ],
      "source": [
        "#@title Training + Finetuning RidgeClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "alphas = [0.1, 1.0, 10.0, 100.0]\n",
        "\n",
        "for a in alphas:\n",
        "    model = RidgeClassifier(alpha=a, class_weight=\"balanced\")\n",
        "    model.fit(X_train_s, y_train)\n",
        "    pred = model.predict(X_val_s)\n",
        "    print(f\"alpha={a} | acc={accuracy_score(y_val, pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pYH_E2pLFMq",
        "outputId": "d35993ce-153c-4679-c2a4-edb430f76d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACC: 0.6\n"
          ]
        }
      ],
      "source": [
        "#@title Training Polymonial Logistic\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = Pipeline([\n",
        "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    (\"clf\", LogisticRegression(\n",
        "        C=1.0,\n",
        "        max_iter=3000,\n",
        "        class_weight=\"balanced\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "model.fit(X_train_s, y_train)\n",
        "pred = model.predict(X_val_s)\n",
        "print(\"ACC:\", accuracy_score(y_val, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McAYKRhsNjrX",
        "outputId": "16addd47-c6a0-4494-dd9f-edd71731b5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training MLP with hidden_layer_sizes=(16,) ---\n",
            "Validation ACC: 0.6\n",
            "\n",
            "--- Training MLP with hidden_layer_sizes=(32,) ---\n",
            "Validation ACC: 0.5875\n",
            "\n",
            "--- Training MLP with hidden_layer_sizes=(64, 32) ---\n",
            "Validation ACC: 0.596875\n",
            "\n",
            "--- Training MLP with hidden_layer_sizes=(128, 64) ---\n",
            "Validation ACC: 0.671875\n",
            "\n",
            "=== BEST CONFIG ===\n",
            "hidden_layer_sizes: (128, 64)\n",
            "Best Validation ACC: 0.671875\n"
          ]
        }
      ],
      "source": [
        "#@title Training + Finetuning MLP\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Danh sách các cấu hình hidden layers để thử\n",
        "configs = [\n",
        "    (16,),       # 1 layer nhỏ\n",
        "    (32,),\n",
        "    (64, 32),    # 2 layer\n",
        "    (128, 64),\n",
        "]\n",
        "\n",
        "best_acc = -1\n",
        "best_config = None\n",
        "best_model = None\n",
        "\n",
        "for cfg in configs:\n",
        "    print(f\"\\n--- Training MLP with hidden_layer_sizes={cfg} ---\")\n",
        "    mlp = MLPClassifier(\n",
        "        hidden_layer_sizes=cfg,\n",
        "        activation=\"relu\",\n",
        "        solver=\"adam\",\n",
        "        max_iter=500,\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=10,\n",
        "        random_state=42\n",
        "    )\n",
        "    mlp.fit(X_train_s, y_train)\n",
        "    pred = mlp.predict(X_val_s)\n",
        "    acc = accuracy_score(y_val, pred)\n",
        "    print(\"Validation ACC:\", acc)\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_config = cfg\n",
        "        best_model = mlp\n",
        "\n",
        "print(\"\\n=== BEST CONFIG ===\")\n",
        "print(\"hidden_layer_sizes:\", best_config)\n",
        "print(\"Best Validation ACC:\", best_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLDD3SRDOosJ",
        "outputId": "d3cf7439-8ee1-4ace-dff2-92b3701b0a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polynomial feature shape: (1440, 152)\n",
            "LR | C=  1.0 | Validation ACC=0.6031\n",
            "LR | C= 10.0 | Validation ACC=0.5437\n",
            "LR | C= 50.0 | Validation ACC=0.5344\n",
            "\n",
            "=== BEST LOGISTIC REGRESSION ===\n",
            "C=1.0 | ACC=0.6031\n",
            "MLP | cfg=(64, 32) | act=relu | ACC=0.6062\n",
            "MLP | cfg=(64, 32) | act=tanh | ACC=0.6219\n",
            "MLP | cfg=(128, 64) | act=relu | ACC=0.6750\n",
            "MLP | cfg=(128, 64) | act=tanh | ACC=0.6531\n",
            "MLP | cfg=(64, 64) | act=relu | ACC=0.6250\n",
            "MLP | cfg=(64, 64) | act=tanh | ACC=0.6438\n",
            "\n",
            "=== BEST MLP ===\n",
            "hidden_layer_sizes=(128, 64) | activation=relu | ACC=0.6750\n"
          ]
        }
      ],
      "source": [
        "#@title Grid search LR + MLP\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Tạo polynomial features nhẹ ---\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train_s)\n",
        "X_val_poly   = poly.transform(X_val_s)\n",
        "print(\"Polynomial feature shape:\", X_train_poly.shape)\n",
        "\n",
        "# --- Grid search Logistic Regression ---\n",
        "C_values = [1.0, 10.0, 50.0]\n",
        "best_lr_acc = -1\n",
        "best_lr_model = None\n",
        "best_lr_C = None\n",
        "\n",
        "for C in C_values:\n",
        "    lr = LogisticRegression(\n",
        "        C=C,\n",
        "        max_iter=500,\n",
        "        solver='lbfgs',\n",
        "        class_weight='balanced',\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    lr.fit(X_train_poly, y_train)\n",
        "    pred = lr.predict(X_val_poly)\n",
        "    acc = accuracy_score(y_val, pred)\n",
        "    print(f\"LR | C={C:>5} | Validation ACC={acc:.4f}\")\n",
        "    if acc > best_lr_acc:\n",
        "        best_lr_acc = acc\n",
        "        best_lr_model = lr\n",
        "        best_lr_C = C\n",
        "\n",
        "print(f\"\\n=== BEST LOGISTIC REGRESSION ===\")\n",
        "print(f\"C={best_lr_C} | ACC={best_lr_acc:.4f}\")\n",
        "\n",
        "# --- Grid search MLP 2 lớp ---\n",
        "mlp_configs = [\n",
        "    (64, 32),\n",
        "    (128, 64),\n",
        "    (64, 64)\n",
        "]\n",
        "activations = ['relu', 'tanh']\n",
        "\n",
        "best_mlp_acc = -1\n",
        "best_mlp_model = None\n",
        "best_mlp_cfg = None\n",
        "best_mlp_act = None\n",
        "\n",
        "for cfg in mlp_configs:\n",
        "    for act in activations:\n",
        "        mlp = MLPClassifier(\n",
        "            hidden_layer_sizes=cfg,\n",
        "            activation=act,\n",
        "            solver='adam',\n",
        "            max_iter=500,\n",
        "            early_stopping=True,\n",
        "            n_iter_no_change=10,\n",
        "            alpha=1e-4,\n",
        "            random_state=42\n",
        "        )\n",
        "        mlp.fit(X_train_s, y_train)\n",
        "        pred = mlp.predict(X_val_s)\n",
        "        acc = accuracy_score(y_val, pred)\n",
        "        print(f\"MLP | cfg={cfg} | act={act:>4} | ACC={acc:.4f}\")\n",
        "        if acc > best_mlp_acc:\n",
        "            best_mlp_acc = acc\n",
        "            best_mlp_model = mlp\n",
        "            best_mlp_cfg = cfg\n",
        "            best_mlp_act = act\n",
        "\n",
        "print(f\"\\n=== BEST MLP ===\")\n",
        "print(f\"hidden_layer_sizes={best_mlp_cfg} | activation={best_mlp_act} | ACC={best_mlp_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1F078DcQ3BB",
        "outputId": "b7e01bfb-dc84-4b06-e063-42b65dca1446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final feature shape: (1440, 44)\n",
            "\n",
            "LOGISTIC REGRESSION ACC: 0.6531\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.50      0.60        40\n",
            "           1       0.80      0.93      0.86        40\n",
            "           2       0.58      0.47      0.52        40\n",
            "           3       0.60      0.88      0.71        40\n",
            "           4       0.73      0.90      0.81        40\n",
            "           5       0.58      0.72      0.64        40\n",
            "           6       0.53      0.47      0.50        40\n",
            "           7       0.67      0.35      0.46        40\n",
            "\n",
            "    accuracy                           0.65       320\n",
            "   macro avg       0.65      0.65      0.64       320\n",
            "weighted avg       0.65      0.65      0.64       320\n",
            "\n",
            "\n",
            "MLP (128,64,tanh) ACC: 0.6719\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.45      0.55        40\n",
            "           1       0.80      0.88      0.83        40\n",
            "           2       0.49      0.47      0.48        40\n",
            "           3       0.65      0.88      0.74        40\n",
            "           4       0.82      1.00      0.90        40\n",
            "           5       0.72      0.70      0.71        40\n",
            "           6       0.49      0.50      0.49        40\n",
            "           7       0.69      0.50      0.58        40\n",
            "\n",
            "    accuracy                           0.67       320\n",
            "   macro avg       0.67      0.67      0.66       320\n",
            "weighted avg       0.67      0.67      0.66       320\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Feature engineering\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Feature engineering ---\n",
        "def mel_to_chroma(X_mel):\n",
        "    \"\"\"\n",
        "    Chroma-like features từ log-mel (n_samples, 16) -> (n_samples, 12)\n",
        "    \"\"\"\n",
        "    n_samples, n_bins = X_mel.shape\n",
        "    chroma = np.zeros((n_samples, 12))\n",
        "    for i in range(12):\n",
        "        bins_idx = [i, (i+12)%n_bins] if n_bins>12 else [i]\n",
        "        chroma[:, i] = X_mel[:, bins_idx].mean(axis=1)\n",
        "    chroma = chroma / (chroma.sum(axis=1, keepdims=True) + 1e-6)\n",
        "    return chroma\n",
        "\n",
        "# Delta features\n",
        "def delta_features(X):\n",
        "    return np.diff(X, axis=1, prepend=0)\n",
        "\n",
        "# Combine features\n",
        "X_train_feat = np.concatenate([\n",
        "    X_train_s,                      # original 16-dim\n",
        "    mel_to_chroma(X_train_s),       # 12-dim chroma-like\n",
        "    delta_features(X_train_s)       # 16-dim delta\n",
        "], axis=1)\n",
        "\n",
        "X_val_feat = np.concatenate([\n",
        "    X_val_s,\n",
        "    mel_to_chroma(X_val_s),\n",
        "    delta_features(X_val_s)\n",
        "], axis=1)\n",
        "\n",
        "print(\"Final feature shape:\", X_train_feat.shape)\n",
        "\n",
        "# --- Standard scaling ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_feat)\n",
        "X_val_scaled   = scaler.transform(X_val_feat)\n",
        "\n",
        "# --- Logistic Regression C=10 ---\n",
        "lr = LogisticRegression(\n",
        "    C=10.0,\n",
        "    max_iter=500,\n",
        "    solver='lbfgs',\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "pred_lr = lr.predict(X_val_scaled)\n",
        "acc_lr = accuracy_score(y_val, pred_lr)\n",
        "print(f\"\\nLOGISTIC REGRESSION ACC: {acc_lr:.4f}\")\n",
        "print(classification_report(y_val, pred_lr))\n",
        "\n",
        "# --- MLP (128,64, tanh) ---\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(128, 64),\n",
        "    activation='tanh',\n",
        "    solver='adam',\n",
        "    max_iter=500,\n",
        "    early_stopping=True,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=42\n",
        ")\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "pred_mlp = mlp.predict(X_val_scaled)\n",
        "acc_mlp = accuracy_score(y_val, pred_mlp)\n",
        "print(f\"\\nMLP (128,64,tanh) ACC: {acc_mlp:.4f}\")\n",
        "print(classification_report(y_val, pred_mlp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr7UbxxSRcbt",
        "outputId": "dceeeb56-2647-4762-844d-2a6f6c00ac1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before polynomial features: (1440, 44)\n",
            "After polynomial features: (1440, 1034)\n",
            "\n",
            "LOGISTIC REGRESSION ACC: 0.6031\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.50      0.52        40\n",
            "           1       0.64      0.57      0.61        40\n",
            "           2       0.49      0.70      0.58        40\n",
            "           3       0.65      0.50      0.56        40\n",
            "           4       0.87      1.00      0.93        40\n",
            "           5       0.73      0.60      0.66        40\n",
            "           6       0.37      0.45      0.40        40\n",
            "           7       0.65      0.50      0.56        40\n",
            "\n",
            "    accuracy                           0.60       320\n",
            "   macro avg       0.62      0.60      0.60       320\n",
            "weighted avg       0.62      0.60      0.60       320\n",
            "\n",
            "\n",
            "MLP (128,64,tanh) ACC: 0.6344\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.53      0.56        40\n",
            "           1       0.68      0.62      0.65        40\n",
            "           2       0.58      0.65      0.61        40\n",
            "           3       0.79      0.68      0.73        40\n",
            "           4       0.75      0.97      0.85        40\n",
            "           5       0.82      0.68      0.74        40\n",
            "           6       0.35      0.40      0.37        40\n",
            "           7       0.58      0.55      0.56        40\n",
            "\n",
            "    accuracy                           0.63       320\n",
            "   macro avg       0.64      0.63      0.63       320\n",
            "weighted avg       0.64      0.63      0.63       320\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Feature engineering (Polynomial feature)\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Feature engineering ---\n",
        "def mel_to_chroma(X_mel):\n",
        "    n_samples, n_bins = X_mel.shape\n",
        "    chroma = np.zeros((n_samples, 12))\n",
        "    for i in range(12):\n",
        "        bins_idx = [i, (i+12)%n_bins] if n_bins>12 else [i]\n",
        "        chroma[:, i] = X_mel[:, bins_idx].mean(axis=1)\n",
        "    chroma = chroma / (chroma.sum(axis=1, keepdims=True) + 1e-6)\n",
        "    return chroma\n",
        "\n",
        "def delta_features(X):\n",
        "    return np.diff(X, axis=1, prepend=0)\n",
        "\n",
        "# Combine features: original + chroma + delta\n",
        "X_train_feat = np.concatenate([\n",
        "    X_train_s,\n",
        "    mel_to_chroma(X_train_s),\n",
        "    delta_features(X_train_s)\n",
        "], axis=1)\n",
        "X_val_feat = np.concatenate([\n",
        "    X_val_s,\n",
        "    mel_to_chroma(X_val_s),\n",
        "    delta_features(X_val_s)\n",
        "], axis=1)\n",
        "\n",
        "print(\"Before polynomial features:\", X_train_feat.shape)\n",
        "\n",
        "# --- Polynomial features degree 2 ---\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train_feat)\n",
        "X_val_poly   = poly.transform(X_val_feat)\n",
        "\n",
        "print(\"After polynomial features:\", X_train_poly.shape)\n",
        "\n",
        "# --- Standard scaling ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
        "X_val_scaled   = scaler.transform(X_val_poly)\n",
        "\n",
        "# --- Logistic Regression C=10 ---\n",
        "lr = LogisticRegression(\n",
        "    C=10.0,\n",
        "    max_iter=500,\n",
        "    solver='lbfgs',\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "pred_lr = lr.predict(X_val_scaled)\n",
        "acc_lr = accuracy_score(y_val, pred_lr)\n",
        "print(f\"\\nLOGISTIC REGRESSION ACC: {acc_lr:.4f}\")\n",
        "print(classification_report(y_val, pred_lr))\n",
        "\n",
        "# --- MLP (128,64, tanh) ---\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(128, 64),\n",
        "    activation='tanh',\n",
        "    solver='adam',\n",
        "    max_iter=500,\n",
        "    early_stopping=True,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=42\n",
        ")\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "pred_mlp = mlp.predict(X_val_scaled)\n",
        "acc_mlp = accuracy_score(y_val, pred_mlp)\n",
        "print(f\"\\nMLP (128,64,tanh) ACC: {acc_mlp:.4f}\")\n",
        "print(classification_report(y_val, pred_mlp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZmawqJLTMh3",
        "outputId": "cca00b53-0a0a-4913-805e-46018e193ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== TRAINING CONFIG ===\n",
            "{'layers': (128, 64), 'activation': 'tanh', 'use_rbf': False}\n",
            "Validation ACC: 0.653125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.50      0.58        40\n",
            "           1       0.80      0.90      0.85        40\n",
            "           2       0.36      0.40      0.38        40\n",
            "           3       0.67      0.88      0.76        40\n",
            "           4       0.78      1.00      0.88        40\n",
            "           5       0.77      0.60      0.68        40\n",
            "           6       0.49      0.45      0.47        40\n",
            "           7       0.65      0.50      0.56        40\n",
            "\n",
            "    accuracy                           0.65       320\n",
            "   macro avg       0.65      0.65      0.64       320\n",
            "weighted avg       0.65      0.65      0.64       320\n",
            "\n",
            "\n",
            "=== TRAINING CONFIG ===\n",
            "{'layers': (128, 64), 'activation': 'tanh', 'use_rbf': True}\n",
            "Validation ACC: 0.203125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.12      0.11        40\n",
            "           1       0.26      0.25      0.25        40\n",
            "           2       0.18      0.17      0.18        40\n",
            "           3       0.13      0.12      0.13        40\n",
            "           4       0.30      0.40      0.34        40\n",
            "           5       0.16      0.15      0.16        40\n",
            "           6       0.04      0.03      0.03        40\n",
            "           7       0.41      0.38      0.39        40\n",
            "\n",
            "    accuracy                           0.20       320\n",
            "   macro avg       0.20      0.20      0.20       320\n",
            "weighted avg       0.20      0.20      0.20       320\n",
            "\n",
            "\n",
            "=== TRAINING CONFIG ===\n",
            "{'layers': (256, 128, 64), 'activation': 'tanh', 'use_rbf': False}\n",
            "Validation ACC: 0.646875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.53      0.58        40\n",
            "           1       0.73      0.93      0.81        40\n",
            "           2       0.34      0.35      0.35        40\n",
            "           3       0.63      0.82      0.72        40\n",
            "           4       0.77      1.00      0.87        40\n",
            "           5       0.78      0.62      0.69        40\n",
            "           6       0.50      0.45      0.47        40\n",
            "           7       0.79      0.47      0.59        40\n",
            "\n",
            "    accuracy                           0.65       320\n",
            "   macro avg       0.65      0.65      0.64       320\n",
            "weighted avg       0.65      0.65      0.64       320\n",
            "\n",
            "\n",
            "=== TRAINING CONFIG ===\n",
            "{'layers': (256, 128, 64), 'activation': 'tanh', 'use_rbf': True}\n",
            "Validation ACC: 0.215625\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.05      0.07      0.06        40\n",
            "           1       0.31      0.35      0.33        40\n",
            "           2       0.12      0.10      0.11        40\n",
            "           3       0.28      0.17      0.22        40\n",
            "           4       0.33      0.45      0.38        40\n",
            "           5       0.17      0.15      0.16        40\n",
            "           6       0.03      0.03      0.03        40\n",
            "           7       0.43      0.40      0.42        40\n",
            "\n",
            "    accuracy                           0.22       320\n",
            "   macro avg       0.22      0.22      0.21       320\n",
            "weighted avg       0.22      0.22      0.21       320\n",
            "\n",
            "\n",
            "=== TRAINING CONFIG ===\n",
            "{'layers': (128, 64), 'activation': 'relu', 'use_rbf': False}\n",
            "Validation ACC: 0.671875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.53      0.60        40\n",
            "           1       0.89      0.82      0.86        40\n",
            "           2       0.42      0.60      0.49        40\n",
            "           3       0.70      0.78      0.74        40\n",
            "           4       0.85      1.00      0.92        40\n",
            "           5       0.83      0.62      0.71        40\n",
            "           6       0.46      0.55      0.50        40\n",
            "           7       0.70      0.47      0.57        40\n",
            "\n",
            "    accuracy                           0.67       320\n",
            "   macro avg       0.70      0.67      0.67       320\n",
            "weighted avg       0.70      0.67      0.67       320\n",
            "\n",
            "\n",
            "=== TRAINING CONFIG ===\n",
            "{'layers': (128, 64), 'activation': 'relu', 'use_rbf': True}\n",
            "Validation ACC: 0.21875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.23      0.18        40\n",
            "           1       0.30      0.28      0.29        40\n",
            "           2       0.19      0.17      0.18        40\n",
            "           3       0.18      0.15      0.16        40\n",
            "           4       0.30      0.40      0.34        40\n",
            "           5       0.19      0.17      0.18        40\n",
            "           6       0.05      0.05      0.05        40\n",
            "           7       0.46      0.30      0.36        40\n",
            "\n",
            "    accuracy                           0.22       320\n",
            "   macro avg       0.23      0.22      0.22       320\n",
            "weighted avg       0.23      0.22      0.22       320\n",
            "\n",
            "\n",
            "=== TRAINING CONFIG ===\n",
            "{'layers': (256, 128, 64), 'activation': 'relu', 'use_rbf': False}\n",
            "Validation ACC: 0.628125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.47      0.51        40\n",
            "           1       0.65      0.93      0.76        40\n",
            "           2       0.35      0.38      0.36        40\n",
            "           3       0.68      0.65      0.67        40\n",
            "           4       0.93      0.95      0.94        40\n",
            "           5       0.70      0.65      0.68        40\n",
            "           6       0.50      0.60      0.55        40\n",
            "           7       0.76      0.40      0.52        40\n",
            "\n",
            "    accuracy                           0.63       320\n",
            "   macro avg       0.64      0.63      0.62       320\n",
            "weighted avg       0.64      0.63      0.62       320\n",
            "\n",
            "\n",
            "=== TRAINING CONFIG ===\n",
            "{'layers': (256, 128, 64), 'activation': 'relu', 'use_rbf': True}\n",
            "Validation ACC: 0.246875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      0.17      0.15        40\n",
            "           1       0.36      0.42      0.39        40\n",
            "           2       0.19      0.17      0.18        40\n",
            "           3       0.34      0.25      0.29        40\n",
            "           4       0.40      0.47      0.43        40\n",
            "           5       0.13      0.15      0.14        40\n",
            "           6       0.03      0.03      0.03        40\n",
            "           7       0.44      0.30      0.36        40\n",
            "\n",
            "    accuracy                           0.25       320\n",
            "   macro avg       0.25      0.25      0.25       320\n",
            "weighted avg       0.25      0.25      0.25       320\n",
            "\n",
            "\n",
            "=== BEST MLP CONFIG ===\n",
            "Config: {'layers': (128, 64), 'activation': 'relu', 'use_rbf': False}\n",
            "Validation ACC: 0.671875\n"
          ]
        }
      ],
      "source": [
        "#@title Kernel approximation for MLP\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Feature scaling ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_s)\n",
        "X_val_scaled   = scaler.transform(X_val_s)\n",
        "\n",
        "# --- Define configurations to try ---\n",
        "mlp_configs = [\n",
        "    {\"layers\": (128, 64), \"activation\": \"tanh\", \"use_rbf\": False},\n",
        "    {\"layers\": (128, 64), \"activation\": \"tanh\", \"use_rbf\": True},\n",
        "    {\"layers\": (256, 128, 64), \"activation\": \"tanh\", \"use_rbf\": False},\n",
        "    {\"layers\": (256, 128, 64), \"activation\": \"tanh\", \"use_rbf\": True},\n",
        "    {\"layers\": (128, 64), \"activation\": \"relu\", \"use_rbf\": False},\n",
        "    {\"layers\": (128, 64), \"activation\": \"relu\", \"use_rbf\": True},\n",
        "    {\"layers\": (256, 128, 64), \"activation\": \"relu\", \"use_rbf\": False},\n",
        "    {\"layers\": (256, 128, 64), \"activation\": \"relu\", \"use_rbf\": True},\n",
        "]\n",
        "\n",
        "best_acc = -1\n",
        "best_config = None\n",
        "best_model = None\n",
        "\n",
        "for cfg in mlp_configs:\n",
        "    print(\"\\n=== TRAINING CONFIG ===\")\n",
        "    print(cfg)\n",
        "\n",
        "    # Prepare features\n",
        "    if cfg[\"use_rbf\"]:\n",
        "        rbf_feature = RBFSampler(gamma=0.5, n_components=128, random_state=42)\n",
        "        X_train_feat = rbf_feature.fit_transform(X_train_scaled)\n",
        "        X_val_feat   = rbf_feature.transform(X_val_scaled)\n",
        "    else:\n",
        "        X_train_feat = X_train_scaled\n",
        "        X_val_feat   = X_val_scaled\n",
        "\n",
        "    # Train MLP\n",
        "    mlp = MLPClassifier(\n",
        "        hidden_layer_sizes=cfg[\"layers\"],\n",
        "        activation=cfg[\"activation\"],\n",
        "        solver=\"adam\",\n",
        "        max_iter=500,\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=10,\n",
        "        random_state=42\n",
        "    )\n",
        "    mlp.fit(X_train_feat, y_train)\n",
        "    pred = mlp.predict(X_val_feat)\n",
        "    acc = accuracy_score(y_val, pred)\n",
        "\n",
        "    print(\"Validation ACC:\", acc)\n",
        "    print(classification_report(y_val, pred))\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_config = cfg\n",
        "        best_model = mlp\n",
        "\n",
        "print(\"\\n=== BEST MLP CONFIG ===\")\n",
        "print(\"Config:\", best_config)\n",
        "print(\"Validation ACC:\", best_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Hsg-wHUrzF",
        "outputId": "7135afb3-80d8-4771-e673-db971fa6e8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported quantized MLP weights to mlp_weights.h\n"
          ]
        }
      ],
      "source": [
        "#@title Export best model weight to .h\n",
        "import numpy as np\n",
        "\n",
        "HEADER_FILE = \"mlp_weights.h\"\n",
        "PREFIX = \"MLP\"\n",
        "\n",
        "# Input scale\n",
        "x_max = np.percentile(np.abs(X_train_scaled), 99.9)\n",
        "INPUT_SCALE = 127.0 / x_max\n",
        "\n",
        "mlp_best = best_model\n",
        "\n",
        "coefs = mlp_best.coefs_            # list of (in_dim, out_dim)\n",
        "intercepts = mlp_best.intercepts_  # list of (out_dim,)\n",
        "\n",
        "with open(HEADER_FILE, \"w\") as f:\n",
        "    f.write(\"#pragma once\\n\\n\")\n",
        "    f.write(\"#include <stdint.h>\\n\\n\")\n",
        "\n",
        "    f.write(\"// ===== Quantization config =====\\n\")\n",
        "    f.write(f\"#define {PREFIX}_INPUT_SCALE {INPUT_SCALE:.8f}f\\n\\n\")\n",
        "\n",
        "    prev_scale = INPUT_SCALE\n",
        "\n",
        "    for layer_idx, (W, b) in enumerate(zip(coefs, intercepts)):\n",
        "        # sklearn: W shape = (in_dim, out_dim)\n",
        "        in_dim, out_dim = W.shape\n",
        "\n",
        "        # transpose cho C: (out_dim, in_dim)\n",
        "        W = W.T\n",
        "\n",
        "        # ---- Quantize weights ----\n",
        "        W_max = np.max(np.abs(W))\n",
        "        W_scale = 127.0 / W_max if W_max != 0 else 1.0\n",
        "        W_q = np.round(W * W_scale).astype(np.int8)\n",
        "\n",
        "        # ---- Quantize bias (INT32, đúng chuẩn) ----\n",
        "        b_scale = prev_scale * W_scale\n",
        "        b_q = np.round(b * b_scale).astype(np.int32)\n",
        "\n",
        "        # ---- Write metadata ----\n",
        "        f.write(f\"// ===== Layer {layer_idx} =====\\n\")\n",
        "        f.write(f\"#define {PREFIX}_L{layer_idx}_IN  {in_dim}\\n\")\n",
        "        f.write(f\"#define {PREFIX}_L{layer_idx}_OUT {out_dim}\\n\")\n",
        "        f.write(f\"#define {PREFIX}_L{layer_idx}_W_SCALE {W_scale:.8f}f\\n\")\n",
        "        f.write(f\"#define {PREFIX}_L{layer_idx}_B_SCALE {b_scale:.8f}f\\n\\n\")\n",
        "\n",
        "        # ---- Write weights ----\n",
        "        f.write(f\"const int8_t {PREFIX}_W{layer_idx}[{out_dim}][{in_dim}] = {{\\n\")\n",
        "        for row in W_q:\n",
        "            f.write(\"  { \" + \", \".join(map(str, row)) + \" },\\n\")\n",
        "        f.write(\"};\\n\\n\")\n",
        "\n",
        "        # ---- Write bias ----\n",
        "        f.write(f\"const int32_t {PREFIX}_B{layer_idx}[{out_dim}] = {{\\n\")\n",
        "        f.write(\"  \" + \", \".join(map(str, b_q)) + \"\\n\")\n",
        "        f.write(\"};\\n\\n\")\n",
        "\n",
        "        prev_scale = b_scale\n",
        "\n",
        "print(f\"Exported quantized MLP weights to {HEADER_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model and scaler\n",
        "import joblib\n",
        "joblib.dump(best_model, \"chord_mlp_model.pkl\")\n",
        "joblib.dump(scaler, \"chord_scaler.pkl\")\n",
        "print(\"Saved chord model to chord_mlp_model.pkl and scaler to chord_scaler.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
