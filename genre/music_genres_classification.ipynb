{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa41f70",
   "metadata": {},
   "source": [
    "Project's objective: Music Genre Classification\n",
    "1. Dataset: GZTAN https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification/data\n",
    "2. Model: MLP (2-layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee5b41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d837bcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of dataset path:\n",
      "['features_30_sec.csv', 'features_3_sec.csv', 'genres_original', 'images_original']\n",
      "\n",
      "genres_original found:\n",
      "['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check what's in the downloaded dataset\n",
    "path = './GZTAN'\n",
    "print(\"Contents of dataset path:\")\n",
    "print(os.listdir(path))\n",
    "\n",
    "# Try to find genres_original\n",
    "preferred = os.path.join(path, 'genres_original')\n",
    "if os.path.exists(preferred):\n",
    "    genres_dir = preferred\n",
    "    print(\"\\ngenres_original found:\")\n",
    "    print(list(os.listdir(genres_dir)))\n",
    "else:\n",
    "    print(f\"\\ngenres_original NOT found at {preferred}\")\n",
    "    # Search for it\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if 'genres_original' in dirs:\n",
    "            genres_dir = os.path.join(root, 'genres_original')\n",
    "            print(f\"Found genres_original at: {genres_dir}\")\n",
    "            print(list(os.listdir(genres_dir))[:10])  # first 10 items\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad44ff",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d84a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>3714.560359</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>3869.682242</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>3997.639160</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>3568.300218</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>3469.992864</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "0   66149          0.335406         0.091048  0.130405  0.003521   \n",
       "1   66149          0.343065         0.086147  0.112699  0.001450   \n",
       "2   66149          0.346815         0.092243  0.132003  0.004620   \n",
       "3   66149          0.363639         0.086856  0.132565  0.002448   \n",
       "4   66149          0.335579         0.088129  0.143289  0.001701   \n",
       "\n",
       "   spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "0             1773.065032          167541.630869              1972.744388   \n",
       "1             1816.693777           90525.690866              2010.051501   \n",
       "2             1788.539719          111407.437613              2084.565132   \n",
       "3             1655.289045          111952.284517              1960.039988   \n",
       "4             1630.656199           79667.267654              1948.503884   \n",
       "\n",
       "   spectral_bandwidth_var  rolloff_mean  ...  mfcc16_var  mfcc17_mean  \\\n",
       "0           117335.771563   3714.560359  ...   39.687145    -3.241280   \n",
       "1            65671.875673   3869.682242  ...   64.748276    -6.055294   \n",
       "2            75124.921716   3997.639160  ...   67.336563    -1.768610   \n",
       "3            82913.639269   3568.300218  ...   47.739452    -3.841155   \n",
       "4            60204.020268   3469.992864  ...   30.336359     0.664582   \n",
       "\n",
       "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n",
       "0   36.488243     0.722209   38.099152    -5.050335   33.618073    -0.243027   \n",
       "1   40.677654     0.159015   51.264091    -2.837699   97.030830     5.784063   \n",
       "2   28.348579     2.378768   45.717648    -1.938424   53.050835     2.517375   \n",
       "3   28.337118     1.218588   34.770935    -3.580352   50.836224     3.630866   \n",
       "4   45.880913     1.689446   51.363583    -3.392489   26.738789     0.536961   \n",
       "\n",
       "   mfcc20_var  label  \n",
       "0   43.771767  blues  \n",
       "1   59.943081  blues  \n",
       "2   33.105122  blues  \n",
       "3   32.023678  blues  \n",
       "4   29.146694  blues  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = os.path.join(path, 'features_3_sec.csv')\n",
    "\n",
    "# if not found, search under path\n",
    "if not os.path.exists(csv_path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if 'features_3_sec.csv' in files:\n",
    "            csv_path = os.path.join(root, 'features_3_sec.csv')\n",
    "            break\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"CSV not found under {path}. Check dataset download.\")\n",
    "\n",
    "data = pd.read_csv(csv_path)\n",
    "data = data.iloc[:, 1:]  # drop index column\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "844d5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "y = data['label'] # genre variable.\n",
    "X = data.loc[:, data.columns != 'label'] #select all columns but not the labels\n",
    "\n",
    "#### NORMALIZE X ####\n",
    "\n",
    "# Normalize so everything is on the same scale.\n",
    "\n",
    "cols = X.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# new data frame with the new scaled data.\n",
    "X = pd.DataFrame(np_scaled, columns = cols)\n",
    "min_vals = min_max_scaler.data_min_\n",
    "max_vals = min_max_scaler.data_max_\n",
    "print(min_vals.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d59725b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75daead",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61c9ce-60b5-4236-ae4f-2d0f8daaa424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "mlp_pipeline = Pipeline([\n",
    "    (\"minmax\", MinMaxScaler()),\n",
    "    (\"mlp\", MLPClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "mlp_param_grid = {\n",
    "    \"mlp__hidden_layer_sizes\": [(64,), (64, 32), (128, 64)],\n",
    "    \"mlp__activation\": [\"relu\"],\n",
    "    \"mlp__alpha\": [1e-4, 1e-3, 1e-2],\n",
    "    \"mlp__learning_rate_init\": [1e-3, 5e-4],\n",
    "    \"mlp__max_iter\": [200, 300, 350]\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(\n",
    "    mlp_pipeline,\n",
    "    mlp_param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "mlp_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best MLP params:\", mlp_grid.best_params_)\n",
    "\n",
    "best_mlp = mlp_grid.best_estimator_\n",
    "y_pred_mlp = best_mlp.predict(X_test)\n",
    "\n",
    "print(\"MLP (tuned) results\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "print(confusion_matrix(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d3d83d3-6029-46e2-ad38-af1964baa575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genre_mlp_model.pkl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_mlp, \"genre_mlp_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85087280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(min_max_scaler, \"gztan_minmax_scaler.pkl\")\n",
    "print(min_max_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "191f6509-38b4-4f88-b6cc-1761b22dd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_int8(arr):\n",
    "    \"\"\"\n",
    "    Symmetric per-tensor int8 quantization\n",
    "    return: q_arr, scale\n",
    "    \"\"\"\n",
    "    max_val = np.max(np.abs(arr))\n",
    "    scale = max_val / 127.0 if max_val != 0 else 1.0\n",
    "    q = np.round(arr / scale).astype(np.int8)\n",
    "    return q, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c172cd-2440-4ab4-813e-f05da131b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported genre_mlp_int8.h with corrected N_CLASSES and multi-layer support\n"
     ]
    }
   ],
   "source": [
    "best_mlp = joblib.load(\"genre_mlp_model.pkl\")\n",
    "min_vals = min_max_scaler.data_min_.astype(np.float32)\n",
    "max_vals = min_max_scaler.data_max_.astype(np.float32)\n",
    "\n",
    "mlp_model = best_mlp.named_steps[\"mlp\"]\n",
    "mlp_scaler = best_mlp.named_steps[\"scaler\"]\n",
    "\n",
    "# Extract weights and biases for all layers\n",
    "coefs = mlp_model.coefs_\n",
    "intercepts = mlp_model.intercepts_\n",
    "n_layers = len(coefs)  # Total layers (input + hidden + output)\n",
    "\n",
    "# Quantize all weights and biases\n",
    "q_coefs = []\n",
    "s_coefs = []\n",
    "q_intercepts = []\n",
    "s_intercepts = []\n",
    "for i in range(n_layers):\n",
    "    qW, sW = quantize_int8(coefs[i])\n",
    "    qb, sb = quantize_int8(intercepts[i])\n",
    "    q_coefs.append(qW)\n",
    "    s_coefs.append(sW)\n",
    "    q_intercepts.append(qb)\n",
    "    s_intercepts.append(sb)\n",
    "\n",
    "mean = mlp_scaler.mean_.astype(np.float32)\n",
    "scale = mlp_scaler.scale_.astype(np.float32)\n",
    "\n",
    "with open(\"genre_mlp_int8.h\", \"w\") as f:\n",
    "    f.write(\"// INT8 MLP (multi-layer) for ESP32\\n\")\n",
    "    f.write(\"#pragma once\\n\")\n",
    "    f.write(\"#include <stdint.h>\\n\\n\")\n",
    "    \n",
    "    # Defines\n",
    "    f.write(f\"#define N_FEATURES {coefs[0].shape[0]}\\n\")\n",
    "    f.write(f\"#define N_CLASSES {coefs[-1].shape[1]}\\n\")  # Correct: Use output layer size\n",
    "    f.write(f\"#define N_HIDDEN_LAYERS {n_layers - 1}\\n\")  # Number of hidden layers\n",
    "    \n",
    "    # Hidden layer sizes (array for dynamic access)\n",
    "    hidden_sizes = [coefs[i].shape[1] for i in range(n_layers - 1)]  # Sizes of hidden layers\n",
    "    f.write(f\"static const int HIDDEN_SIZES[N_HIDDEN_LAYERS] = {{{', '.join(map(str, hidden_sizes))}}};\\n\\n\")\n",
    "    \n",
    "    # Input scaler\n",
    "    f.write(\"static const float INPUT_MEAN[N_FEATURES] = {\" + \",\".join(map(str, mean)) + \"};\\n\")\n",
    "    f.write(\"static const float INPUT_SCALE[N_FEATURES] = {\" + \",\".join(map(str, scale)) + \"};\\n\\n\")\n",
    "    \n",
    "    # MinMax scaler (from training)\n",
    "    f.write(\"static const float GENRE_MIN[N_FEATURES] = {\\n\")\n",
    "    for v in min_vals:\n",
    "        f.write(f\"  {v:.8f}f,\\n\")\n",
    "    f.write(\"};\\n\\n\")\n",
    "\n",
    "    f.write(\"static const float GENRE_MAX[N_FEATURES] = {\\n\")\n",
    "    for v in max_vals:\n",
    "        f.write(f\"  {v:.8f}f,\\n\")\n",
    "    f.write(\"};\\n\\n\")\n",
    "\n",
    "    # Scales for weights and biases\n",
    "    for i in range(n_layers):\n",
    "        layer_name = f\"LAYER_{i+1}\" if i < n_layers - 1 else \"OUTPUT\"\n",
    "        f.write(f\"static const float W{i+1}_SCALE = {s_coefs[i]};\\n\")\n",
    "        f.write(f\"static const float B{i+1}_SCALE = {s_intercepts[i]};\\n\")\n",
    "    \n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # Weights (2D arrays)\n",
    "    for i in range(n_layers):\n",
    "        in_size = coefs[i].shape[0]\n",
    "        out_size = coefs[i].shape[1]\n",
    "        layer_name = f\"W{i+1}\"\n",
    "        f.write(f\"static const int8_t {layer_name}[{in_size}][{out_size}] = {{\\n\")\n",
    "        for row in q_coefs[i]:\n",
    "            f.write(\"{\" + \",\".join(map(str, row.tolist())) + \"},\\n\")\n",
    "        f.write(\"};\\n\\n\")\n",
    "    \n",
    "    # Biases (1D arrays)\n",
    "    for i in range(n_layers):\n",
    "        out_size = coefs[i].shape[1]\n",
    "        layer_name = f\"B{i+1}\"\n",
    "        f.write(f\"static const int8_t {layer_name}[{out_size}] = {{\" + \",\".join(map(str, q_intercepts[i].tolist())) + \"}};\\n\\n\")\n",
    "\n",
    "print(\"Exported genre_mlp_int8.h with corrected N_CLASSES and multi-layer support\")\n",
    "\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f722f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess mp3 sample\n",
    "import librosa\n",
    "\n",
    "def extract_full_features(mp3_path, sr=22050, duration=3):\n",
    "    \"\"\"Extract features from MP3 matching training CSV columns.\"\"\"\n",
    "    y, _ = librosa.load(mp3_path, sr=sr, duration=duration)\n",
    "    features = {}\n",
    "\n",
    "    # length\n",
    "    features['length'] = len(y)\n",
    "\n",
    "    # chroma_stft\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features['chroma_stft_mean'] = chroma_stft.mean()\n",
    "    features['chroma_stft_var'] = chroma_stft.var()\n",
    "\n",
    "    # rms\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    features['rms_mean'] = rms.mean()\n",
    "    features['rms_var'] = rms.var()\n",
    "\n",
    "    # spectral_centroid\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    features['spectral_centroid_mean'] = spec_cent.mean()\n",
    "    features['spectral_centroid_var'] = spec_cent.var()\n",
    "\n",
    "    # spectral_bandwidth\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    features['spectral_bandwidth_mean'] = spec_bw.mean()\n",
    "    features['spectral_bandwidth_var'] = spec_bw.var()\n",
    "\n",
    "    # rolloff\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    features['rolloff_mean'] = rolloff.mean()\n",
    "    features['rolloff_var'] = rolloff.var()\n",
    "\n",
    "    # zero_crossing_rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features['zero_crossing_rate_mean'] = zcr.mean()\n",
    "    features['zero_crossing_rate_var'] = zcr.var()\n",
    "\n",
    "    # harmony & perceptr\n",
    "    try:\n",
    "        harmony, perceptr = librosa.effects.hpss(y)\n",
    "        features['harmony_mean'] = harmony.mean()\n",
    "        features['harmony_var'] = harmony.var()\n",
    "        features['perceptr_mean'] = perceptr.mean()\n",
    "        features['perceptr_var'] = perceptr.var()\n",
    "    except Exception:\n",
    "        features['harmony_mean'] = 0\n",
    "        features['harmony_var'] = 0\n",
    "        features['perceptr_mean'] = 0\n",
    "        features['perceptr_var'] = 0\n",
    "\n",
    "    # tempo\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    features['tempo'] = tempo\n",
    "\n",
    "    # MFCCs (20 coefficients, mean + var = 40 total)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    for i in range(1, 21):\n",
    "        features[f'mfcc{i}_mean'] = mfcc[i-1].mean()\n",
    "        features[f'mfcc{i}_var'] = mfcc[i-1].var()\n",
    "\n",
    "    # Build feature vector in correct order matching training columns\n",
    "    feat_vec = []\n",
    "    for col in cols:\n",
    "        if col in features:\n",
    "            val = features[col]\n",
    "            # ensure scalar (not array)\n",
    "            feat_vec.append(float(val) if np.isscalar(val) else float(val))\n",
    "        else:\n",
    "            print(f\"Warning: column '{col}' not found in extracted features, using 0\")\n",
    "            feat_vec.append(0.0)\n",
    "    \n",
    "    return np.array(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ca56349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\300.mp3\n",
      "country (confidence: 0.5833)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\301.mp3\n",
      "blues (confidence: 0.8081)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\302.mp3\n",
      "pop (confidence: 0.7670)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\303.mp3\n",
      "classical (confidence: 0.9675)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\304.mp3\n",
      "pop (confidence: 0.9704)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\305.mp3\n",
      "country (confidence: 0.6323)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\306.mp3\n",
      "jazz (confidence: 1.0000)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\307.mp3\n",
      "classical (confidence: 1.0000)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\308.mp3\n",
      "hiphop (confidence: 0.5222)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\309.mp3\n",
      "disco (confidence: 0.9518)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\310.mp3\n",
      "country (confidence: 1.0000)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\311.mp3\n",
      "country (confidence: 0.7664)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\312.mp3\n",
      "disco (confidence: 0.7310)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\313.mp3\n",
      "blues (confidence: 0.5118)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\314.mp3\n",
      "disco (confidence: 0.9999)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\315.mp3\n",
      "classical (confidence: 1.0000)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\316.mp3\n",
      "country (confidence: 0.7627)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\317.mp3\n",
      "rock (confidence: 0.9972)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\318.mp3\n",
      "metal (confidence: 0.8793)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\319.mp3\n",
      "country (confidence: 0.9997)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\320.mp3\n",
      "rock (confidence: 0.9993)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\321.mp3\n",
      "disco (confidence: 0.9999)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\322.mp3\n",
      "country (confidence: 0.6333)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\323.mp3\n",
      "jazz (confidence: 0.9869)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\324.mp3\n",
      "pop (confidence: 0.9723)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\325.mp3\n",
      "pop (confidence: 0.9767)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\326.mp3\n",
      "pop (confidence: 0.7956)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\327.mp3\n",
      "reggae (confidence: 0.7621)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\328.mp3\n",
      "rock (confidence: 0.6808)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\329.mp3\n",
      "country (confidence: 0.9810)\n",
      "\n",
      "MP3: C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\\330.mp3\n",
      "metal (confidence: 0.5032)\n"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "from pathlib import Path \n",
    "pipeline = joblib.load(\"genre_mlp_model.pkl\") \n",
    "minmax_scaler = joblib.load(\"gztan_minmax_scaler.pkl\")\n",
    "test_path = r\"C:\\workspace\\HMUD\\deam\\DEAM_audio\\MEMD_audio\" \n",
    "for i in range(300, 331): \n",
    "    mp3_file = os.path.join(test_path, f\"{i}.mp3\") \n",
    "    if not Path(mp3_file).exists(): \n",
    "        print(\"File not found:\", mp3_file) \n",
    "        continue \n",
    "    feat_vec = extract_full_features(mp3_file) \n",
    "    feat_scaled = minmax_scaler.transform(feat_vec.reshape(1, -1)) \n",
    "    genre = pipeline.predict(feat_scaled.reshape(1, -1))[0] \n",
    "    prob = pipeline.predict_proba(feat_scaled.reshape(1, -1))[0] \n",
    "    print(f\"\\nMP3: {mp3_file}\") \n",
    "    print(f\"{genre} (confidence: {prob.max():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9bad14b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('mlp',\n",
      "                 MLPClassifier(alpha=0.001, hidden_layer_sizes=(128, 64),\n",
      "                               learning_rate_init=0.0005, max_iter=300,\n",
      "                               random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "febcd4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reggae'] [[2.92611212e-62 3.54992118e-48 7.67296766e-51 7.68428017e-39\n",
      "  1.45726478e-23 5.29078192e-45 2.71604792e-47 3.61544294e-09\n",
      "  9.99999996e-01 1.16886845e-61]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fake = np.random.rand(feat_vec.shape[0]).reshape(1, -1)\n",
    "print(pipeline.predict(fake), pipeline.predict_proba(fake))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models to models/\n"
     ]
    }
   ],
   "source": [
    "# serialize the model and scaler\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Save artifacts\n",
    "outdir = Path(\"models\")\n",
    "outdir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"Saved models to models/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
